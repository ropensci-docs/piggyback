[{"path":"https://docs.ropensci.org/piggyback/CODE_OF_CONDUCT.html","id":null,"dir":"","previous_headings":"","what":"Contributor Code of Conduct","title":"Contributor Code of Conduct","text":"contributors maintainers project, pledge respect people contribute reporting issues, posting feature requests, updating documentation, submitting pull requests patches, activities. committed making participation project harassment-free experience everyone, regardless level experience, gender, gender identity expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion. Examples unacceptable behavior participants include use sexual language imagery, derogatory comments personal attacks, trolling, public private harassment, insults, unprofessional conduct. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct. Project maintainers follow Code Conduct may removed project team. Instances abusive, harassing, otherwise unacceptable behavior may reported opening issue contacting one project maintainers. Code Conduct adapted Contributor Covenant (http://contributor-covenant.org), version 1.0.0, available http://contributor-covenant.org/version/1/0/0/","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://docs.ropensci.org/piggyback/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) 2018 Carl Boettiger  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. piggyback Copyright (C) 2018 Carl Boettiger This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://docs.ropensci.org/piggyback/articles/alternatives.html","id":"piggyback-vs-the-alternatives","dir":"Articles","previous_headings":"","what":"piggyback vs the alternatives","title":"Piggyback comparison to alternatives","text":"many alternatives piggyback, considerable experience haven’t found ticked boxes : Free storage Can integrated private code / private workflows Simple practical deploy continuous integration Works well private data Minimal configuration","code":""},{"path":"https://docs.ropensci.org/piggyback/articles/alternatives.html","id":"git-lfs","dir":"Articles","previous_headings":"piggyback vs the alternatives","what":"Git LFS","title":"Piggyback comparison to alternatives","text":"Git LFS provides closest user experience going . stands alternatives providing best authentication experience (relying directly standard git authentication mechanisms https, ssh keys, app integration), provides legitimate version control data. However, many show-stoppers using Git LFS . GitHub pricing & resulting problems GitHub’s fork / PR model. Described eloquently . Basically, despite generous rates free data options everywhere else, GitHub’s LFS storage bandwidth cost lot, also make impossible public forks pull request repository. Technically problem GitHub’s LFS (since stems pricing rules); can avoided using LFS GitLab platform, Jim Hester described. Still, proved unsuccessful , still faces big issue git-lfs: Overwrites git . Git LFS just integrated git – replaces authentic git engine git-lfs, identical git command can different behaviors machine git-lfs installed vs just plain git. Maybe fine professional team “” git-lfs, constant source pitfalls working students moving machines authentic git installed. difficulties supporting pull requests etc also related – sense, git-lfs repository, ’re really using entirely new version control system isn’t going 100% compatible nearly-ubiquitous authentic git.","code":""},{"path":"https://docs.ropensci.org/piggyback/articles/alternatives.html","id":"amazon-s3","dir":"Articles","previous_headings":"piggyback vs the alternatives","what":"Amazon S3","title":"Piggyback comparison to alternatives","text":"Amazon S3 perhaps universal obvious go-place online-available public private data storage. 5 GB/mo free tier nice pricing reasonable incremental . easily industry-standard solution, still probably best way go many cases. probably scalable solution large data, built support/integration larger query services like Apache Spark / sparklyr. falls short use case though authentication area. require students create GitHub account courses lab group. don’t like requiring third-party accounts, one fundamental daily use classroom research, continue using service afterwards. particularly don’t like people create complex accounts might even use much class afterwards, just deal pesky minor issue data file just little big GitHub. Amazon’s authentication also much complex GitHub’s passwords tokens, process uploading downloading data S3 (though aws.s3 R package rather nice remedy , doesn’t conform user API aws-cli (python) tool, leaving odd quirks patterns don’t match standard Linux commands.) Together, make significantly difficult deploy quick solution moving private data around private repositories.","code":""},{"path":"https://docs.ropensci.org/piggyback/articles/alternatives.html","id":"scientific-repositories-with-private-storage","dir":"Articles","previous_headings":"piggyback vs the alternatives","what":"Scientific repositories with private storage","title":"Piggyback comparison to alternatives","text":"scientific research purposes, ideal solution. Encouraging researchers submit data repository time publication always challenge, since inevitably involves time & effort immediate benefit researcher relatively minimal. uploading data repository served immediate practical purpose facilitating collaboration, backing possibly versioning data, etc, research process rather said done, much compelling. Several repositories permit sharing private data, least threshold, including DataONE figshare. Unfortunately, time, found interfaces R tooling limited cumbersome everyday use.","code":""},{"path":"https://docs.ropensci.org/piggyback/articles/alternatives.html","id":"datastorr","dir":"Articles","previous_headings":"piggyback vs the alternatives","what":"datastorr","title":"Piggyback comparison to alternatives","text":"piggyback approach partly inspired strategy used datastorr package, also uploads data GitHub releases. datastorr envisions rather different workflow around storage strategy, based concept R “data package” rather Git LFS. fan “data package” approach general – think data stored platform agnostic way, .Rdata files, often want first download data disk read dedicated functions, load “auto-magically” package. latter issue particularly important data files larger can conveniently fit working memory, better accessed database (e.g. SQLite tabular data, postgis spatial data, etc). terms practical implementation, datastorr also creates new release every time data file updated, rather letting overwrite files. principle piggyback let version data way well, simply create new release first using pb_new_release(tag=\"v2\") whatever tag like. opted workflow since reality, versioning data releases way technically equivalent creating new folder new version data storing – unlike true git commits, release assets datastorr creates can easily deleted overwritten. still believe permanent versioned archives like Zenodo used long-term versioned distribution. Meanwhile, day--day use often want overwrite data files recent versions. (case ‘data’ files often created upstream data /possibly-long-running code, tracked convenience. often change result continued work upstream processing code. Perhaps case many users attention paid versioning.)","code":""},{"path":"https://docs.ropensci.org/piggyback/articles/alternatives.html","id":"sharding-on-github","dir":"Articles","previous_headings":"piggyback vs the alternatives","what":"Sharding on GitHub","title":"Piggyback comparison to alternatives","text":"Another creative solution (hack), least file types, break large files multiple smaller files, commit one many GitHub repositories. sharding sometimes legitimate strategy, many obvious practical disadvantages limitations.","code":""},{"path":"https://docs.ropensci.org/piggyback/articles/cloud_native.html","id":"data-too-big-to-fit-in-memory","dir":"Articles","previous_headings":"","what":"Data Too Big To Fit In Memory","title":"Cloud native workflows with piggyback","text":"One primary advantages piggyback ability store lot fairly large files. also potentially source frustrations: piggyback assets may potentially quite large (large fit RAM) difficult work uploaded release. substantial rapidly growing number packages able work data -disk without reading whole thing memory, including terra, stars, sf large spatial assets, well arrow duckdb tabular data. Going step , libraries now also make possible skip ‘read twice’ pattern downloading disk reading disk, can let skip ever reading whole data file R - instance, spatial packages can use GDAL’s virtual file system. arrow duckdb can similar tricks parquet csv files, allowing users leverage functions like dplyr::select() dplyr::filter() directly remote data source access subset rows/columns need. Subsetting data directly URL manner thus performance benefit reading directly memory also added benefit allowing efficient bigger--RAM workflows. sometimes referred cloud-native workflows.","code":""},{"path":"https://docs.ropensci.org/piggyback/articles/cloud_native.html","id":"nflverse-play-by-play","dir":"Articles","previous_headings":"","what":"nflverse play by play","title":"Cloud native workflows with piggyback","text":"vignette shows examples using duckdb querying larger datasets, using example data nflverse project NFL football analytics. (Consult nflverse’s nflreadr package looking work NFL data beyond example) nflverse/nflverse-data data repository organized one release specific dataframe typically sharded multiple files (file formats) season. ’s brief glimpse looks piggyback lens: ’ll look play play release data try calculate summary statistics, without downloading reading RAM…","code":"pb_releases(\"nflverse/nflverse-data\") #> # A data.frame: 20 × 10 #>   release_name release_id release_body        tag_name draft created_at published_at #>   <chr>             <int> <chr>               <chr>    <lgl> <chr>      <chr>        #> 1 rosters        58152863 \"Roster data, acce… rosters  FALSE 2022-01-2… 2022-01-28T… #> 2 player_stats   58152881 \"Play by play data… player_… FALSE 2022-01-2… 2022-01-28T… #> 3 pbp            58152862 \"Play by play data… pbp      FALSE 2022-01-2… 2022-01-28T… #> 4 pfr_advstats   58152981 \"PFR Adv Stats dat… pfr_adv… FALSE 2022-01-2… 2022-01-28T… #> 5 depth_charts   58152948 \"Depth chart data,… depth_c… FALSE 2022-01-2… 2022-01-28T… #> # ℹ 15 more rows #> # ℹ 3 more variables: html_url <chr>, upload_url <chr>, n_assets <int> #> # ℹ Use `print(n = ...)` to see more rows  pb_list(repo = \"nflverse/nflverse-data\", tag = \"pbp\") #> # A data.frame: 148 × 6 #>    file_name                     size timestamp           tag   owner repo  #>    <chr>                        <int> <dttm>              <chr> <chr> <chr> #>  1 play_by_play_2023.rds     12308832 2023-12-26 17:10:52 pbp   nflv… nflv… #>  2 play_by_play_2023.parquet 17469950 2023-12-26 17:11:02 pbp   nflv… nflv… #>  3 play_by_play_2023.csv     84490319 2023-12-26 17:10:58 pbp   nflv… nflv… #>  4 play_by_play_2022.rds     14387514 2023-02-28 09:25:26 pbp   nflv… nflv… #>  5 play_by_play_2022.parquet 20003378 2023-02-28 09:25:35 pbp   nflv… nflv… #>  6 play_by_play_2022.csv     97205016 2023-02-28 09:25:31 pbp   nflv… nflv… #> # ℹ 143 more rows #> # ℹ Use `print(n = ...)` to see more rows  pb_download_url(   \"play_by_play_2023.csv\",    repo = \"nflverse/nflverse-data\",    tag = \"pbp\" ) |>    read.csv() |>    dplyr::glimpse() #> Rows: 42,066 #> Columns: 372 #> $ play_id                              <int> 1, 39, 55, 77, 102, 124, 147… #> $ game_id                              <chr> \"2023_01_ARI_WAS\", \"2023_01_… #> $ home_team                            <chr> \"WAS\", \"WAS\", \"WAS\", \"WAS\", … #> $ away_team                            <chr> \"ARI\", \"ARI\", \"ARI\", \"ARI\", … #> $ season_type                          <chr> \"REG\", \"REG\", \"REG\", \"REG\", … #> $ week                                 <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… #> $ posteam                              <chr> \"\", \"WAS\", \"WAS\", \"WAS\", \"WA… #> $ posteam_type                         <chr> \"\", \"home\", \"home\", \"home\", … #> $ defteam                              <chr> \"\", \"ARI\", \"ARI\", \"ARI\", \"AR… #> $ yardline_100                         <int> NA, 35, 75, 72, 66, 64, 64, … #> $ down                                 <int> NA, NA, 1, 2, 3, 1, 2, 1, 2,… #> $ play_type                            <chr> \"\", \"kickoff\", \"run\", \"pass\"…"},{"path":"https://docs.ropensci.org/piggyback/articles/cloud_native.html","id":"duckdb","dir":"Articles","previous_headings":"","what":"DuckDB","title":"Cloud native workflows with piggyback","text":"Packages used section: First, initialize duckdb install/load httpfs (short http file system) Next, ’ll need get relevant play--play URLs release - can pb_download_url - pass duckdb’s read_parquet function Now, can construct SQL query summarizes data: can also turn view query dbplyr/dplyr instead: Using duckdb certainly adds little verbosity - exchange, ’ve managed query summarize 20+ parquet files summing 1M+ rows without load memory!","code":"library(piggyback) library(DBI) library(duckdb) library(dplyr) library(glue) library(tictoc) conn <- DBI::dbConnect(duckdb::duckdb()) DBI::dbExecute(conn, \"INSTALL 'httpfs'; LOAD 'httpfs';\") tictoc::tic() pbp_urls <- pb_download_url(repo = \"nflverse/nflverse-data\", tag = \"pbp\") # keep only the ones matching the desired regex pattern, \"play_by_play_####.parquet\" pbp_urls <- pbp_urls[grepl(\"play_by_play_\\\\d+.parquet\", pbp_urls)]  query <- glue::glue_sql(\"SELECT COUNT(*) as row_count FROM read_parquet([{pbp_urls *}])\", .con = conn)  DBI::dbGetQuery(conn = conn, query) #>   row_count #> 1   1190783 tictoc::toc() #> 2.845 sec elapsed tictoc::tic() query <- glue::glue_sql(   \"   SELECT     season,     posteam,     play_type,     COUNT(play_id) AS n_plays,     AVG(epa) AS epa_per_play   FROM read_parquet([{pbp_urls *}], filename = true)   WHERE filename SIMILAR TO '.*(2021|2022|2023).*'   AND (pass = 1 OR rush = 1)   GROUP BY season, posteam, play_type   ORDER BY season DESC, posteam ASC, n_plays DESC   \",   .con = conn )  DBI::dbGetQuery(conn = conn, query) #> # A data.frame: 288 × 5 #>    season posteam play_type n_plays epa_per_play #>     <int> <chr>   <chr>       <dbl>        <dbl> #>  1   2023 ARI     pass          539      -0.231  #>  2   2023 ARI     run           391       0.0351 #>  3   2023 ARI     no_play        48       0.191  #>  4   2023 ATL     pass          499      -0.0738 #>  5   2023 ATL     run           465      -0.103  #> # ℹ 283 more rows #> # ℹ Use `print(n = ...)` to see more rows  tictoc::toc() #> 3.343 sec elapsed query <- glue::glue_sql(   \"   CREATE VIEW pbp AS   SELECT     *   FROM read_parquet([{pbp_urls *}], filename = true)   \",   .con = conn ) DBI::dbExecute(conn, query) pbp <- dplyr::tbl(conn, \"pbp\") tictoc::tic() pbp |>    dplyr::filter(grepl(\"2021|2022|2023\", filename), pass == 1 | rush == 1) |>    dplyr::summarise(     n_plays = dplyr::n(),     epa_per_play = mean(epa, na.rm = TRUE),     .by = c(season, posteam, play_type)   ) |>    dplyr::arrange(     desc(season), posteam, desc(n_plays)   ) |>    dplyr::collect() #> # A tibble: 288 × 5 #>    season posteam play_type n_plays epa_per_play #>     <int> <chr>   <chr>       <dbl>        <dbl> #>  1   2023 ARI     pass          539      -0.231  #>  2   2023 ARI     run           391       0.0351 #>  3   2023 ARI     no_play        48       0.191  #>  4   2023 ATL     pass          499      -0.0738 #>  5   2023 ATL     run           465      -0.103  #> # ℹ 283 more rows #> # ℹ Use `print(n = ...)` to see more rows tictoc::toc() #> 3.491 sec elapsed"},{"path":"https://docs.ropensci.org/piggyback/articles/cloud_native.html","id":"duckdbfs","dir":"Articles","previous_headings":"DuckDB","what":"duckdbfs","title":"Cloud native workflows with piggyback","text":"duckdbfs developed wrap latter workflow single function call accepts vector URLs:","code":"library(duckdbfs) pbp <- duckdbfs::open_dataset(pbp_urls, filename = TRUE) tictoc::tic() pbp |>    dplyr::filter(grepl(\"2021|2022|2023\", filename), pass == 1 | rush == 1) |>    dplyr::summarise(     n_plays = dplyr::n(),     epa_per_play = mean(epa, na.rm = TRUE),     .by = c(season, posteam, play_type)   ) |>    dplyr::arrange(     desc(season), posteam, desc(n_plays)   ) |>    dplyr::collect() #> # A tibble: 288 × 5 #>    season posteam play_type n_plays epa_per_play #>     <int> <chr>   <chr>       <dbl>        <dbl> #>  1   2023 ARI     pass          539      -0.231  #>  2   2023 ARI     run           391       0.0351 #>  3   2023 ARI     no_play        48       0.191  #>  4   2023 ATL     pass          499      -0.0738 #>  5   2023 ATL     run           465      -0.103  #> # ℹ 283 more rows #> # ℹ Use `print(n = ...)` to see more rows tictoc::toc() #> 3.492 sec elapsed"},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"why-piggyback","dir":"Articles","previous_headings":"","what":"Why piggyback?","title":"Piggyback Data atop your GitHub Repository!","text":"piggyback grew needs students classroom research group, frequently need work data files somewhat larger one can conveniently manage committing directly GitHub. frequently want share run code depends >50MB data files machines, continuous integration, larger computational servers, data sharing quickly becomes bottleneck. GitHub allows repositories attach files 2 GB releases way distribute large files associated project source code. limit number files bandwidth deliver .","code":""},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"authentication","dir":"Articles","previous_headings":"","what":"Authentication","title":"Piggyback Data atop your GitHub Repository!","text":"authentication required download data public GitHub repositories using piggyback. Nevertheless, recommends setting token possible avoid rate limits. upload data repository, download data private repositories, need authenticate first. piggyback uses GitHub Personal Access Token (PAT) devtools, usethis, friends use (gh::gh_token()). current best practice managing GitHub credentials detailed usethis vignette. can also add token environment variable, may useful situations use piggyback non-interactively (.e. automated scripts). relevant steps: Create GitHub Token usethis::use_git_ignore(\".Renviron\") update gitignore - prevents accidentally committing token GitHub usethis::edit_r_environ(\"project\") open Renviron file, add token, e.g. GITHUB_PAT=ghp_a1b2c3d4e5f6g7 via Sys.setenv(GITHUB_PAT = \"ghp_a1b2c3d4e5f6g7\") console adhoc usage. Avoid adding line R scripts – remember, goal avoid writing private token file might shared, even privately.","code":""},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"download-files","dir":"Articles","previous_headings":"","what":"Download Files","title":"Piggyback Data atop your GitHub Repository!","text":"Download file release: default behaviors know : repo argument piggyback functions default detecting relevant GitHub repo based current working directory’s git configs, many cases can omit repo argument. tag argument functions defaults “latest”, typically refers recently created release repository, unless release specifically named “latest” marked different release “latest” via GitHub UI. dest argument defaults current working directory (\".\"). use tempdir() meet CRAN policies purposes examples. file argument pb_download defaults NULL, download files connected given release: use_timestamps argument defaults TRUE - notice , iris2.tsv.gz downloaded. use_timestamps TRUE, pb_download() compare local file timestamp GitHub file timestamp, download file changed. pb_download() also includes arguments control progress bar particular files downloaded.","code":"pb_download(   file = \"iris2.tsv.gz\",    dest = tempdir(),   repo = \"cboettig/piggyback-tests\",   tag = \"v0.0.1\"   ) #> ℹ Downloading \"iris2.tsv.gz\"... #>   |======================================================| 100% fs::dir_tree(tempdir()) #> /tmp/RtmpWxJSZj #> └── iris2.tsv.gz pb_download(   repo = \"cboettig/piggyback-tests\",   tag = \"v0.0.1\",   dest = tempdir() ) #> ℹ Downloading \"diamonds.tsv.gz\"... #>   |======================================================| 100% #> ℹ Downloading \"iris.tsv.gz\"... #>   |======================================================| 100% #> ℹ Downloading \"iris.tsv.xz\"... #>   |======================================================| 100% fs::dir_tree(tempdir()) #> /tmp/RtmpWxJSZj #> ├── diamonds.tsv.gz #> ├── iris.tsv.gz #> ├── iris.tsv.xz #> └── iris2.tsv.gz"},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"download-urls","dir":"Articles","previous_headings":"Download Files","what":"Download URLs","title":"Piggyback Data atop your GitHub Repository!","text":"Sometimes preferable URL data can read directly. URL can passed another R function, can elegant performant first download files locally. Enter pb_download_url(): default, function returns download URL get visiting release page, right-clicking file, copying link (aka “browser_download_url”). URL served GitHub’s web servers API servers, therefore restrictive rate-limiting. However, URL accessible private repositories, since auth tokens handled GitHub API. can retrieve API download url private repositories passing \"api\" url_type argument: pb_download_url otherwise shares similar default behaviors pb_download file, repo, tag arguments.","code":"pb_download_url(repo = \"cboettig/piggyback-tests\", tag = \"v0.0.1\") #> [1] \"https://github.com/cboettig/piggyback-tests/releases/download/v0.0.1/diamonds.tsv.gz\" #> [2] \"https://github.com/cboettig/piggyback-tests/releases/download/v0.0.1/iris.tsv.gz\"     #> [3] \"https://github.com/cboettig/piggyback-tests/releases/download/v0.0.1/iris.tsv.xz\"     #> [4] \"https://github.com/cboettig/piggyback-tests/releases/download/v0.0.1/iris2.tsv.gz\" pb_download_url(repo = \"cboettig/piggyback-tests\", tag = \"v0.0.1\", url_type = \"api\") #> [1] https://api.github.com/repos/cboettig/piggyback-tests/releases/assets/44261315 #> [2] https://api.github.com/repos/cboettig/piggyback-tests/releases/assets/41841778 #> [3] https://api.github.com/repos/cboettig/piggyback-tests/releases/assets/18538636 #> [4] https://api.github.com/repos/cboettig/piggyback-tests/releases/assets/8990141"},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"reading-data-for-r-usage","dir":"Articles","previous_headings":"","what":"Reading data for R usage","title":"Piggyback Data atop your GitHub Repository!","text":"piggyback supports several general patterns reading data R, increasing degrees performance/efficiency (complexity): pb_download() files disk reading files function reads disk memory pb_download_url() set URLs passing URLs function retrieves URLs directly memory Disk-based workflows require downloading files first can perform queries reading memory Cloud-native workflows can perform queries directly URLs reading memory recommend latter two approaches cases performance efficiency matter, vignettes examples: - cloud native workflows - disk native workflows","code":""},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"reading-files","dir":"Articles","previous_headings":"Reading data for R usage","what":"Reading files","title":"Piggyback Data atop your GitHub Repository!","text":"pb_read() wrapper first pattern - downloads file temp file, reads file memory, deletes temporary file. works public private repositories, handling authentication hood: default, pb_read programmed use following read_function corresponding file extensions: “.csv”, “.csv.gz”, “.csv.xz” read utils::read.csv() “.tsv”, “.tsv.gz”, “.tsv.xz” read utils::read.delim() “.rds” read readRDS() “.json” read jsonlite::fromJSON() “.parquet” read arrow::read_parquet() “.txt” read readLines() file extension list, pb_read raise error ask provide read_function - can also use parameter override default read_function : read_function can provided long accepts filename first argument, can pass additional parameters via ...:","code":"pb_read(\"mtcars.rds\", repo = \"tanho63/piggyback-private\") #> # A data.frame: 32 × 11 #>     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1  21       6   160   110  3.9   2.62  16.5     0     1     4     4 #> 2  21       6   160   110  3.9   2.88  17.0     0     1     4     4 #> 3  22.8     4   108    93  3.85  2.32  18.6     1     1     4     1 #> 4  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1 #> 5  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2 #> # ℹ 27 more rows #> # ℹ 1 more variable: carb <dbl> pb_read(\"mtcars.parquet\", repo = \"tanho63/piggyback-private\") #> # A data.frame: 32 × 11 #>     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1  21       6   160   110  3.9   2.62  16.5     0     1     4     4 #> 2  21       6   160   110  3.9   2.88  17.0     0     1     4     4 #> 3  22.8     4   108    93  3.85  2.32  18.6     1     1     4     1 #> 4  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1 #> 5  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2 #> # ℹ 27 more rows #> # ℹ 1 more variable: carb <dbl> pb_read(   file = \"play_by_play_2023.qs\",    repo = \"nflverse/nflverse-data\",   tag = \"pbp\",   read_function = qs::qread ) #> # A tibble: 42,251 × 372 #>   play_id game_id        old_game_id home_team away_team season_type  week posteam #>     <dbl> <chr>          <chr>       <chr>     <chr>     <chr>       <int> <chr>   #> 1       1 2023_01_ARI_W… 2023091007  WAS       ARI       REG             1 NA      #> 2      39 2023_01_ARI_W… 2023091007  WAS       ARI       REG             1 WAS     #> 3      55 2023_01_ARI_W… 2023091007  WAS       ARI       REG             1 WAS     #> 4      77 2023_01_ARI_W… 2023091007  WAS       ARI       REG             1 WAS     #> 5     102 2023_01_ARI_W… 2023091007  WAS       ARI       REG             1 WAS     #> # ℹ 42,246 more rows #> # ℹ 364 more variables: posteam_type <chr>, defteam <chr>, side_of_field <chr>, #> #   yardline_100 <dbl>, game_date <chr>, quarter_seconds_remaining <dbl>, #> #   half_seconds_remaining <dbl>, game_seconds_remaining <dbl>, game_half <chr>, #> #   quarter_end <dbl>, drive <dbl>, sp <dbl>, qtr <dbl>, down <dbl>, #> #   goal_to_go <dbl>, time <chr>, yrdln <chr>, ydstogo <dbl>, ydsnet <dbl>, #> #   desc <chr>, play_type <chr>, yards_gained <dbl>, shotgun <dbl>, … pb_read(   file = \"play_by_play_2023.csv\",    n_max = 10,   repo = \"nflverse/nflverse-data\",   tag = \"pbp\",   read_function = readr::read_csv ) #> # A tibble: 10 × 372 #>   play_id game_id        old_game_id home_team away_team season_type  week posteam #>     <dbl> <chr>          <chr>       <chr>     <chr>     <chr>       <int> <chr>   #> 1       1 2023_01_ARI_W… 2023091007  WAS       ARI       REG             1 NA      #> 2      39 2023_01_ARI_W… 2023091007  WAS       ARI       REG             1 WAS     #> 3      55 2023_01_ARI_W… 2023091007  WAS       ARI       REG             1 WAS     #> 4      77 2023_01_ARI_W… 2023091007  WAS       ARI       REG             1 WAS     #> 5     102 2023_01_ARI_W… 2023091007  WAS       ARI       REG             1 WAS     #> # ℹ 5 more rows #> # ℹ 364 more variables: posteam_type <chr>, defteam <chr>, side_of_field <chr>, #> #   yardline_100 <dbl>, game_date <chr>, quarter_seconds_remaining <dbl>, #> #   half_seconds_remaining <dbl>, game_seconds_remaining <dbl>, game_half <chr>, #> #   quarter_end <dbl>, drive <dbl>, sp <dbl>, qtr <dbl>, down <dbl>, #> #   goal_to_go <dbl>, time <chr>, yrdln <chr>, ydstogo <dbl>, ydsnet <dbl>, #> #   desc <chr>, play_type <chr>, yards_gained <dbl>, shotgun <dbl>, …"},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"reading-from-urls","dir":"Articles","previous_headings":"Reading data for R usage","what":"Reading from URLs","title":"Piggyback Data atop your GitHub Repository!","text":"efficiently, many read functions accept URLs, including read.csv(), arrow::read_parquet(), readr::read_csv(), data.table::fread(), jsonlite::fromJSON(), reading one file can done passing along output pb_download_url(): functions also accept URLs converted connection wrapping url(), e.g. readRDS(): Note using url() requires close connection reading , else receive warnings leaving open connections. url() approach allows us pass along authentication private repos, e.g. Note arrow accept url() connection time, default pb_read() using private repositories.","code":"pb_download_url(\"mtcars.csv\", repo = \"tanho63/piggyback-tests\", tag = \"v0.0.2\") %>%   read.csv() #> # A data.frame: 32 × 12 #>   X        mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear #>   <chr>  <dbl> <int> <dbl> <int> <dbl> <dbl> <dbl> <int> <int> <int> #> 1 Mazda…  21       6   160   110  3.9   2.62  16.5     0     1     4 #> 2 Mazda…  21       6   160   110  3.9   2.88  17.0     0     1     4 #> 3 Datsu…  22.8     4   108    93  3.85  2.32  18.6     1     1     4 #> 4 Horne…  21.4     6   258   110  3.08  3.22  19.4     1     0     3 #> 5 Horne…  18.7     8   360   175  3.15  3.44  17.0     0     0     3 #> # ℹ 27 more rows #> # ℹ 1 more variable: carb <int> #> # ℹ Use `print(n = ...)` to see more rows pb_url <- pb_download_url(\"mtcars.rds\", repo = \"tanho63/piggyback-tests\", tag = \"v0.0.2\") %>%   url() readRDS(pb_url) #> # A data.frame: 32 × 11 #>     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1  21       6   160   110  3.9   2.62  16.5     0     1     4     4 #> 2  21       6   160   110  3.9   2.88  17.0     0     1     4     4 #> 3  22.8     4   108    93  3.85  2.32  18.6     1     1     4     1 #> 4  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1 #> 5  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2 #> # ℹ 27 more rows #> # ℹ Use `print(n = ...)` to see more rows close(pb_url) pb_url <- pb_download_url(\"mtcars.rds\", repo = \"tanho63/piggyback-private\", url_type = \"api\") %>%   url(     headers = c(       \"Accept\" = \"application/octet-stream\",       \"Authorization\" = paste(\"Bearer\", gh::gh_token())     )   ) readRDS(pb_url) #> # A tibble: 32 × 11 #>     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb #>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1  21       6   160   110  3.9   2.62  16.5     0     1     4     4 #> 2  21       6   160   110  3.9   2.88  17.0     0     1     4     4 #> 3  22.8     4   108    93  3.85  2.32  18.6     1     1     4     1 #> 4  21.4     6   258   110  3.08  3.22  19.4     1     0     3     1 #> 5  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2 #> # ℹ 27 more rows #> # ℹ Use `print(n = ...)` to see more rows close(pb_url)"},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"uploading-data","dir":"Articles","previous_headings":"","what":"Uploading data","title":"Piggyback Data atop your GitHub Repository!","text":"piggyback uploads data GitHub releases. repository doesn’t release yet, piggyback prompt create one - can create release : Create new releases manage multiple versions given data file, organize sets files common topic. can create releases often like, making new release necessary time upload file. maintaining old versions data useful, can stick single release upload data . least one release available, ready upload files. default, pb_upload attach data latest release. Like pb_download(), pb_upload() overwrite file name already attached release file default, unless timestamp previously uploaded version recent. can toggle settings overwrite parameter. pb_upload also accepts vector multiple files upload:","code":"pb_release_create(repo = \"cboettig/piggyback-tests\", tag = \"v0.0.2\") #> ✔ Created new release \"v0.0.2\". ## We'll need some example data first. ## Pro tip: compress your tabular data to save space & speed upload/downloads readr::write_tsv(mtcars, \"mtcars.tsv.gz\")  pb_upload(\"mtcars.tsv.gz\", repo = \"cboettig/piggyback-tests\") #> ℹ Uploading to latest release: \"v0.0.2\". #> ℹ Uploading mtcars.tsv.gz ... #>   |===================================================| 100% library(magrittr) ## upload a folder of data list.files(\"data\") %>%    pb_upload(repo = \"cboettig/piggyback-tests\", tag = \"v0.0.1\")  ## upload certain file extensions list.files(pattern = c(\"*.tsv.gz\", \"*.tif\", \"*.zip\")) %>%    pb_upload(repo = \"cboettig/piggyback-tests\", tag = \"v0.0.1\")"},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"write-r-object-directly-to-release","dir":"Articles","previous_headings":"Uploading data","what":"Write R object directly to release","title":"Piggyback Data atop your GitHub Repository!","text":"pb_write wraps process, essentially allowing upload directly release providing object, filename, repo/tag: Similar pb_read, pb_write pre-programmed write_functions following file extensions: - “.csv”, “.csv.gz”, “.csv.xz” written utils::write.csv() - “.tsv”, “.tsv.gz”, “.tsv.xz” written utils::write.csv(x, filename, sep = '\\t') - “.rds” written saveRDS() - “.json” written jsonlite::write_json() - “.parquet” written arrow::write_parquet() - “.txt” written writeLines() can pass custom functions write_function parameter:","code":"pb_write(mtcars, \"mtcars.rds\", repo = \"cboettig/piggyback-tests\") #> ℹ Uploading to latest release: \"v0.0.2\". #> ℹ Uploading mtcars.rds ... #>   |===================================================| 100% pb_write(   x = mtcars,    file = \"mtcars.csv.gz\",    repo = \"cboettig/piggyback-tests\",    write_function = data.table::fwrite ) #> ℹ Uploading to latest release: \"v0.0.2\". #> ℹ Uploading mtcars.csv.gz ... #>   |===================================================| 100%"},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"deleting-files","dir":"Articles","previous_headings":"","what":"Deleting Files","title":"Piggyback Data atop your GitHub Repository!","text":"Delete file release: Note irreversible unless copy data elsewhere.","code":"pb_delete(file = \"mtcars.tsv.gz\",            repo = \"cboettig/piggyback-tests\",            tag = \"v0.0.1\") #> ℹ Deleted \"mtcars.tsv.gz\" from \"v0.0.1\" release on \"cboettig/piggyback-tests\""},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"listing-files","dir":"Articles","previous_headings":"","what":"Listing Files","title":"Piggyback Data atop your GitHub Repository!","text":"List files currently piggybacking given release. Omit tag see files releases.","code":"pb_list(repo = \"cboettig/piggyback-tests\", tag = \"v0.0.1\") #>         file_name   size           timestamp    tag    owner            repo #> 1 diamonds.tsv.gz 571664 2021-09-07 23:38:31 v0.0.1 cboettig piggyback-tests #> 2     iris.tsv.gz    846 2021-08-05 20:00:09 v0.0.1 cboettig piggyback-tests #> 3     iris.tsv.xz    848 2020-03-07 06:18:32 v0.0.1 cboettig piggyback-tests #> 4    iris2.tsv.gz    846 2018-10-05 17:04:33 v0.0.1 cboettig piggyback-tests"},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"caching","dir":"Articles","previous_headings":"","what":"Caching","title":"Piggyback Data atop your GitHub Repository!","text":"reduce GitHub API calls, piggyback caches pb_releases pb_list timeout 10 minutes default. avoids repeating identical requests update internal record repository data (releases, assets, timestamps, etc) programmatic use. can increase decrease delay setting environment variable seconds, e.g. Sys.setenv(\"piggyback_cache_duration\" = 3600) longer cache Sys.setenv(\"piggyback_cache_duration\" = 0) disable caching, restarting R.","code":""},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"valid-file-names","dir":"Articles","previous_headings":"","what":"Valid file names","title":"Piggyback Data atop your GitHub Repository!","text":"GitHub assets attached release support file paths, sometimes convert special characters (#, %, etc) . throw error (e.g.  file names containing $, @, /). piggyback default using basename() file (.e. use \"mtcars.csv\" provided file path like \"data/mtcars.csv\")","code":""},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"a-note-on-github-releases-vs-data-archiving","dir":"Articles","previous_headings":"","what":"A Note on GitHub Releases vs Data Archiving","title":"Piggyback Data atop your GitHub Repository!","text":"piggyback intended data archiving solution. Importantly, bear mind nothing special multiple “versions” releases, far data assets uploaded piggyback concerned. data files piggyback attaches Release can deleted modified time – creating new release store data assets functional equivalent just creating new directories v0.1, v0.2 store data. (GitHub Releases always pinned particular git tag, code/git-managed contents associated repo immutable, remember data assets just piggyback top repo). Permanent, published data always archived proper data repository DOI, zenodo.org. Zenodo can freely archive public research data files 50 GB size, data strictly versioned (released, DOI always refers version data, new releases given new DOIs). piggyback meant lower friction working data research process, (e.g. provide data accessible collaborators continuous integration systems research process, including private repositories.)","code":""},{"path":"https://docs.ropensci.org/piggyback/articles/piggyback.html","id":"what-will-github-think-of-this","dir":"Articles","previous_headings":"","what":"What will GitHub think of this?","title":"Piggyback Data atop your GitHub Repository!","text":"GitHub documentation time writing endorses use attachments releases solution distributing large files part project:","code":""},{"path":"https://docs.ropensci.org/piggyback/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Carl Boettiger. Author, maintainer, copyright holder. Tan Ho. Author. Mark Padgham. Contributor. Jeffrey O Hanson. Contributor. Kevin Kuo. Contributor.","code":""},{"path":"https://docs.ropensci.org/piggyback/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Boettiger C, Ho T (2024). piggyback: Managing Larger Data GitHub Repository. R package version 0.1.5.9004, https://github.com/ropensci/piggyback, https://docs.ropensci.org/piggyback/.","code":"@Manual{,   title = {piggyback: Managing Larger Data on a GitHub Repository},   author = {Carl Boettiger and Tan Ho},   year = {2024},   note = {R package version 0.1.5.9004, https://github.com/ropensci/piggyback},   url = {https://docs.ropensci.org/piggyback/}, }"},{"path":"https://docs.ropensci.org/piggyback/index.html","id":"piggyback-","dir":"","previous_headings":"","what":"Managing Larger Data on a GitHub Repository","title":"Managing Larger Data on a GitHub Repository","text":"piggyback provides R interface storing files GitHub release assets, convenient way large/binary data files piggyback onto public private GitHub repositories. package includes functions file downloads, uploads, managing releases, passed GitHub API. authentication required download data public repositories.","code":""},{"path":"https://docs.ropensci.org/piggyback/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Managing Larger Data on a GitHub Repository","text":"Install CRAN via: can install development version GitHub either r-universe remotes:","code":"install.packages(\"piggyback\") install.packages(\"piggyback\", repos = c('https://ropensci.r-universe.dev', getOption(\"repos\"))) # install.packages(\"remotes\") remotes::install_github(\"ropensci/piggyback\")"},{"path":"https://docs.ropensci.org/piggyback/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Managing Larger Data on a GitHub Repository","text":"See getting started vignette comprehensive introduction. Download data attached GitHub release: Downloading private repos uploading repo requires authentication, specifically GitHub Personal Access Token (PAT). can stored gh::gh_token() GITHUB_PAT environment variable - information, see vignette notes authentication. can also upload data release. Start creating release: upload : improved performance, can also use piggyback files cloud native workflows query data without downloading first.","code":"library(piggyback) pb_download(\"iris2.tsv.gz\",              repo = \"cboettig/piggyback-tests\",             tag = \"v0.0.1\",             dest = tempdir()) #> ℹ Downloading \"iris2.tsv.gz\"... #> |======================================================| 100% fs::dir_tree(tempdir()) #> /tmp/RtmpWxJSZj #> └── iris2.tsv.gz pb_release_create(repo = \"cboettig/piggyback-tests\", tag = \"v0.0.2\") #> ✔ Created new release \"v0.0.2\". readr::write_tsv(mtcars, \"mtcars.tsv.gz\") pb_upload(\"mtcars.tsv.gz\", repo = \"cboettig/piggyback-tests\") #> ℹ Uploading to latest release: \"v0.0.2\". #> ℹ Uploading mtcars.tsv.gz ... #> |===================================================| 100%"},{"path":"https://docs.ropensci.org/piggyback/index.html","id":"motivations","dir":"","previous_headings":"","what":"Motivations","title":"Managing Larger Data on a GitHub Repository","text":"brief video overview presented part Tan Ho’s RStudioConf2022 talk: https://github.com/ropensci/piggyback/assets/38083823/a1dff640-1bba-4c06-bad2-feda34f47387 piggyback allows store data alongside repository release assets, helps : store files larger 50MB bypass 2GB GitHub repo size limit avoid downsides Git LFS version data flexibly (creating/uploading new release) work public private repositories, free motivations, see discussion alternatives.","code":""},{"path":"https://docs.ropensci.org/piggyback/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Managing Larger Data on a GitHub Repository","text":"Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"https://docs.ropensci.org/piggyback/paper.html","id":null,"dir":"","previous_headings":"","what":"Piggyback: Working with larger data in GitHub","title":"Piggyback: Working with larger data in GitHub","text":"GitHub become central component preserving sharing software-driven analysis academic research [@Ram2013]. scientists adopt workflow, desire manage data associated analysis manner soon emerges. small data can easily committed GitHub repositories along-side source code analysis scripts, files larger 50 MB . Existing work-arounds introduce significant complexity break ease sharing [@Boettiger2018]. package provides simple work-around allowing larger (2 GB) data files piggyback repository assets attached individual GitHub releases. piggyback provides workflow similar Git LFS [@GitLFS], data files can tracked type pushed pulled GitHub dedicated commands. files handled git way, instead uploaded, downloaded, edited directly calls GitHub API [@API3]. data files can versioned manually creating different releases. approach works equally well public private repositories. Data can uploaded downloaded programmatically scripts. authentication required download data public repositories.","code":""},{"path":"https://docs.ropensci.org/piggyback/paper.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Piggyback: Working with larger data in GitHub","text":"long repository least one release, users can upload set specified files current repository release simply passing file names pb_upload(). Specify individual files download using pb_download(), use arguments download data files attached latest release. Alternatively, users can track files given pattern: instance, pb_track(\"*.csv\") track *.csv files repository. use pb_upload(pb_track()) upload currently tracked files. piggyback compares timestamps avoid unnecessary transfer. piggyback package looks GITHUB_TOKEN environmental variable authentication used across GitHub APIs. Details provided introductory vignette [@Boettiger2018b].","code":""},{"path":[]},{"path":"https://docs.ropensci.org/piggyback/reference/dot-check_test_token.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Test PAT — .check_test_token","title":"Check Test PAT — .check_test_token","text":"use fine-grained GitHub Personal Access Token auth testing. function memoised checks token correct permissions various test repositories.","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/dot-check_test_token.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Test PAT — .check_test_token","text":"","code":".check_test_token()"},{"path":"https://docs.ropensci.org/piggyback/reference/dot-check_test_token.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Test PAT — .check_test_token","text":"test_token github token, typically stored TAN_GH_TOKEN test_repos repos used testing","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/dot-check_test_token.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Test PAT — .check_test_token","text":"named vector TRUE FALSE whether token configured can access test repos.","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/dot-check_test_token.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check Test PAT — .check_test_token","text":"following token permissions: Contents (read/write) Metadata (read) following repositories tanho63/piggyback tanho63/piggyback-tests tanho63/piggyback-private (private repository)","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/dot-pb_cache_clear.html","id":null,"dir":"Reference","previous_headings":"","what":"Clear cached functions — .pb_cache_clear","title":"Clear cached functions — .pb_cache_clear","text":"function clears cache memoised piggyback functions.","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/dot-pb_cache_clear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clear cached functions — .pb_cache_clear","text":"","code":".pb_cache_clear()"},{"path":"https://docs.ropensci.org/piggyback/reference/dot-pb_cache_clear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clear cached functions — .pb_cache_clear","text":"invisible: TRUE success","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/dot-pb_cache_clear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clear cached functions — .pb_cache_clear","text":"","code":".pb_cache_clear()"},{"path":"https://docs.ropensci.org/piggyback/reference/guess_read_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Guess read function from file extension — guess_read_function","title":"Guess read function from file extension — guess_read_function","text":"function accepts filename tries return valid function reading .","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/guess_read_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Guess read function from file extension — guess_read_function","text":"","code":"guess_read_function(file)"},{"path":"https://docs.ropensci.org/piggyback/reference/guess_read_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Guess read function from file extension — guess_read_function","text":"file filename parse","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/guess_read_function.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Guess read function from file extension — guess_read_function","text":"function reading file, found","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/guess_read_function.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Guess read function from file extension — guess_read_function","text":"guess_read_function understands following file extensions: rds readRDS csv, csv.gz, csv.xz utils::read.csv tsv, tsv.gz, tsv.xz utils::read.delim parquet arrow::read_parquet txt, txt.gz, txt.xz readLines json, json.gz, json.xz jsonlite::fromJSON","code":""},{"path":[]},{"path":"https://docs.ropensci.org/piggyback/reference/guess_write_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Guess write function from file extension — guess_write_function","title":"Guess write function from file extension — guess_write_function","text":"function accepts filename tries return valid function writing .","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/guess_write_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Guess write function from file extension — guess_write_function","text":"","code":"guess_write_function(file)"},{"path":"https://docs.ropensci.org/piggyback/reference/guess_write_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Guess write function from file extension — guess_write_function","text":"file filename parse","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/guess_write_function.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Guess write function from file extension — guess_write_function","text":"function reading file, found","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/guess_write_function.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Guess write function from file extension — guess_write_function","text":"guess_write_function understands following file extensions: rds saveRDS csv, csv.gz, csv.xz utils::write.csv tsv, tsv.gz, tsv.xz modified utils::write.csv sep set \"\\t\" parquet arrow::write_parquet txt, txt.gz, txt.xz writeLines json, json.gz, json.xz jsonlite::write_json","code":""},{"path":[]},{"path":"https://docs.ropensci.org/piggyback/reference/pb_delete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete an asset attached to a release — pb_delete","title":"Delete an asset attached to a release — pb_delete","text":"Delete asset attached release","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_delete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete an asset attached to a release — pb_delete","text":"","code":"pb_delete(   file = NULL,   repo = guess_repo(),   tag = \"latest\",   .token = gh::gh_token() )"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_delete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete an asset attached to a release — pb_delete","text":"file file(s) deleted release. NULL (default argument omitted), function delete attachments release. delete repo string: GH repository name format \"owner/repo\". Default guess_repo() tries guess based current working directory's git repository tag string: tag GH release, defaults \"latest\" .token GitHub authentication token, see gh::gh_token()","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_delete.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Delete an asset attached to a release — pb_delete","text":"TRUE (invisibly) file found deleted. Otherwise, returns NULL (invisibly) file matching name found.","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_delete.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delete an asset attached to a release — pb_delete","text":"","code":"if (FALSE) { readr::write_tsv(mtcars, \"mtcars.tsv.gz\") ## Upload pb_upload(\"mtcars.tsv.gz\",           repo = \"cboettig/piggyback-tests\",           overwrite = TRUE) pb_delete(\"mtcars.tsv.gz\",           repo = \"cboettig/piggyback-tests\",           tag = \"v0.0.1\") }"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_download.html","id":null,"dir":"Reference","previous_headings":"","what":"Download data from an existing release — pb_download","title":"Download data from an existing release — pb_download","text":"Download data existing release","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_download.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download data from an existing release — pb_download","text":"","code":"pb_download(   file = NULL,   dest = \".\",   repo = guess_repo(),   tag = \"latest\",   overwrite = TRUE,   ignore = \"manifest.json\",   use_timestamps = TRUE,   show_progress = getOption(\"piggyback.verbose\", default = interactive()),   .token = gh::gh_token() )"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_download.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download data from an existing release — pb_download","text":"file character: vector names files downloaded. NULL, assets attached release downloaded. dest character: path destination directory (length one) vector destination filepaths length file. directories path provided must already exist. repo string: GH repository name format \"owner/repo\". Default guess_repo() tries guess based current working directory's git repository tag string: tag GH release, defaults \"latest\" overwrite boolean: local files name overwritten? default TRUE ignore character: vector files ignore (used downloading \"\" via file=NULL) use_timestamps DEPRECATED. show_progress logical, show progress bar shown uploading? Defaults interactive() - can also set globally options(\"piggyback.verbose\") .token GitHub authentication token, see gh::gh_token()","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_download.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download data from an existing release — pb_download","text":"","code":"# \\donttest{ try({    ## Download a specific file.    ## (if dest is omitted, will write to current directory)    dest <- tempdir()    piggyback::pb_download(      \"iris.tsv.gz\",      repo = \"cboettig/piggyback-tests\",      tag = \"v0.0.1\",      dest = dest    )    list.files(dest)    ## Download all files    piggyback::pb_download(      repo = \"cboettig/piggyback-tests\",      tag = \"v0.0.1\",      dest = dest    )    list.files(dest) }) #>  [1] \"bslib-a655ad9af56d1a84d5022504144f9f41\" #>  [2] \"diamonds.tsv.gz\"                        #>  [3] \"downlit\"                                #>  [4] \"file5ae2bb4ecd6\"                        #>  [5] \"file5ae2ee5cbd8\"                        #>  [6] \"file5ae3e236b0c\"                        #>  [7] \"file5ae48477e73\"                        #>  [8] \"file5ae4a506215\"                        #>  [9] \"file5ae756db147\"                        #> [10] \"iris.tsv.gz\"                            #> [11] \"iris.tsv.xz\"                            #> [12] \"iris2.tsv.gz\"                           # \\dontshow{    try(unlink(list.files(dest, full.names = TRUE)))  # } # }"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_download_url.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the download url of a given file — pb_download_url","title":"Get the download url of a given file — pb_download_url","text":"Returns URL download given file. can useful using functions able accept URLs.","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_download_url.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the download url of a given file — pb_download_url","text":"","code":"pb_download_url(   file = NULL,   repo = guess_repo(),   tag = \"latest\",   url_type = c(\"browser\", \"api\"),   .token = gh::gh_token() )"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_download_url.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the download url of a given file — pb_download_url","text":"file character: vector names files downloaded. NULL, assets attached release downloaded. repo string: GH repository name format \"owner/repo\". Default guess_repo() tries guess based current working directory's git repository tag string: tag GH release, defaults \"latest\" url_type choice: one \"browser\" \"api\" - default \"browser\" web-facing URL subject API ratelimits work private repositories. \"api\" URLs work private repos, require GitHub token passed Authorization header (see examples) .token GitHub authentication token, see gh::gh_token()","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_download_url.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the download url of a given file — pb_download_url","text":"URL download file","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_download_url.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the download url of a given file — pb_download_url","text":"","code":"# \\donttest{ try({  # returns browser url by default (and all files if none are specified) browser_url <- pb_download_url(   repo = \"tanho63/piggyback-tests\",   tag = \"v0.0.2\"   ) print(browser_url) utils::read.csv(browser_url[[1]])  # can return api url if desired api_url <- pb_download_url(   \"mtcars.csv\",   repo = \"tanho63/piggyback-tests\",   tag = \"v0.0.2\"   ) print(api_url)  # for public repositories, this will still work utils::read.csv(api_url)  # for private repos, can use httr or curl to fetch and then pass into read function gh_pat <- Sys.getenv(\"GITHUB_PAT\")  if(!identical(gh_pat, \"\")){   resp <- httr::GET(api_url, httr::add_headers(Authorization = paste(\"Bearer\", gh_pat)))   utils::read.csv(text = httr::content(resp, as = \"text\")) }  # or use pb_read which bundles some of this for you  }) #> [1] \"https://github.com/tanho63/piggyback-tests/releases/download/v0.0.2/mtcars.csv\"     #> [2] \"https://github.com/tanho63/piggyback-tests/releases/download/v0.0.2/mtcars.parquet\" #> [3] \"https://github.com/tanho63/piggyback-tests/releases/download/v0.0.2/mtcars.rds\"     #> [1] \"https://github.com/tanho63/piggyback-tests/releases/download/v0.0.2/mtcars.csv\" #> No encoding supplied: defaulting to UTF-8. #>                      X  mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> 1            Mazda RX4 21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> 2        Mazda RX4 Wag 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> 3           Datsun 710 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> 4       Hornet 4 Drive 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #> 5    Hornet Sportabout 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> 6              Valiant 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> 7           Duster 360 14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #> 8            Merc 240D 24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #> 9             Merc 230 22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> 10            Merc 280 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> 11           Merc 280C 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> 12          Merc 450SE 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> 13          Merc 450SL 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> 14         Merc 450SLC 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> 15  Cadillac Fleetwood 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> 16 Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> 17   Chrysler Imperial 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> 18            Fiat 128 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> 19         Honda Civic 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> 20      Toyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> 21       Toyota Corona 21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1 #> 22    Dodge Challenger 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> 23         AMC Javelin 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> 24          Camaro Z28 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> 25    Pontiac Firebird 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> 26           Fiat X1-9 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> 27       Porsche 914-2 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> 28        Lotus Europa 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> 29      Ford Pantera L 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> 30        Ferrari Dino 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> 31       Maserati Bora 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> 32          Volvo 142E 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2 # }"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_list.html","id":null,"dir":"Reference","previous_headings":"","what":"List all assets attached to a release — pb_list","title":"List all assets attached to a release — pb_list","text":"List assets attached release","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List all assets attached to a release — pb_list","text":"","code":"pb_list(repo = guess_repo(), tag = NULL, .token = gh::gh_token())"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List all assets attached to a release — pb_list","text":"repo string: GH repository name format \"owner/repo\". Default guess_repo() tries guess based current working directory's git repository tag release tag(s) want information ? NULL (default), return table available release tags. .token GitHub authentication token, see gh::gh_token()","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List all assets attached to a release — pb_list","text":"data.frame release asset names, release tag, timestamp, owner, repo.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/piggyback/reference/pb_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List all assets attached to a release — pb_list","text":"","code":"if (FALSE) { pb_list(\"cboettig/piggyback-tests\") }"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_read.html","id":null,"dir":"Reference","previous_headings":"","what":"Read one file into memory — pb_read","title":"Read one file into memory — pb_read","text":"convenience wrapper around writing object temporary file uploading specified repo/release. convenience comes cost performance efficiency, since first downloads data disk reads data disk memory. See vignette(\"cloud_native\") alternative ways bypass flow work data directly.","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_read.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read one file into memory — pb_read","text":"","code":"pb_read(   file,   ...,   repo = guess_repo(),   tag = \"latest\",   read_function = guess_read_function(file),   .token = gh::gh_token() )"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_read.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read one file into memory — pb_read","text":"file string: file name ... additional arguments passed read_function file repo string: GH repository name format \"owner/repo\". Default guess_repo() tries guess based current working directory's git repo tag string: tag GH release, defaults \"latest\" read_function function: used read data, file passed first argument additional arguments subsequently passed via .... Default guess_read_function(file) check file extension try find appropriate read function extension one rds, csv, tsv, parquet, txt, json, abort found. .token GitHub authentication token, see gh::gh_token()","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_read.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read one file into memory — pb_read","text":"Result reading file question.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/piggyback/reference/pb_read.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read one file into memory — pb_read","text":"","code":"# \\donttest{ try({ # try block is to avoid CRAN issues and is not required in ordinary usage  piggyback::pb_read(\"mtcars.tsv.gz\", repo = \"cboettig/piggyback-tests\") }) #>     mpg cyl  disp  hp drat    wt  qsec vs am gear carb #> 1  21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #> 2  21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #> 3  22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #> 4  21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #> 5  18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #> 6  18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #> 7  14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #> 8  24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #> 9  22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> 10 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> 11 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> 12 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> 13 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> 14 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> 15 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> 16 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> 17 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> 18 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> 19 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> 20 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> 21 21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1 #> 22 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> 23 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> 24 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> 25 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> 26 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> 27 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> 28 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> 29 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> 30 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> 31 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> 32 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2 # }"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_release_create.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new release on GitHub repo — pb_release_create","title":"Create a new release on GitHub repo — pb_release_create","text":"Create new release GitHub repo","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_release_create.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new release on GitHub repo — pb_release_create","text":"","code":"pb_release_create(   repo = guess_repo(),   tag,   commit = NULL,   name = tag,   body = \"Data release\",   draft = FALSE,   prerelease = FALSE,   .token = gh::gh_token() )"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_release_create.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new release on GitHub repo — pb_release_create","text":"repo Repository name format \"owner/repo\". guess current repo specified. tag tag create release commit Specifies commit-ish value determines Git tag created . Can branch full commit SHA (short hash). Unused git tag already exists. Default: repository's default branch (usually master). name name release. Defaults tag. body Text describing contents tag. default text \"Data release\". draft default FALSE. Set TRUE create draft (unpublished) release. prerelease default FALSE. Set TRUE identify release pre-release. .token GitHub authentication token, see [gh::gh_token()]","code":""},{"path":[]},{"path":"https://docs.ropensci.org/piggyback/reference/pb_release_create.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a new release on GitHub repo — pb_release_create","text":"","code":"if (FALSE) { pb_release_create(\"cboettig/piggyback-tests\", \"v0.0.5\") }"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_release_delete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete release from GitHub repo — pb_release_delete","title":"Delete release from GitHub repo — pb_release_delete","text":"Delete release GitHub repo","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_release_delete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete release from GitHub repo — pb_release_delete","text":"","code":"pb_release_delete(repo = guess_repo(), tag, .token = gh::gh_token())"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_release_delete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete release from GitHub repo — pb_release_delete","text":"repo Repository name format \"owner/repo\". Defaults guess_repo(). tag tag name delete. Must one found pb_releases()$tag_name. .token GitHub authentication token, see [gh::gh_token()]","code":""},{"path":[]},{"path":"https://docs.ropensci.org/piggyback/reference/pb_release_delete.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delete release from GitHub repo — pb_release_delete","text":"","code":"if (FALSE) { pb_release_delete(\"cboettig/piggyback-tests\", \"v0.0.5\") }"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_releases.html","id":null,"dir":"Reference","previous_headings":"","what":"List releases in repository — pb_releases","title":"List releases in repository — pb_releases","text":"function retrieves information releases attached given repository.","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_releases.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List releases in repository — pb_releases","text":"","code":"pb_releases(   repo = guess_repo(),   .token = gh::gh_token(),   verbose = getOption(\"piggyback.verbose\", default = TRUE) )"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_releases.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List releases in repository — pb_releases","text":"repo GitHub repository specification form \"owner/repo\", specified try guess repo based current working directory. .token GitHub API token, defaults gh::gh_token() verbose defaults TRUE, use FALSE silence messages","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_releases.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List releases in repository — pb_releases","text":"dataframe releases available within repository.","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_releases.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List releases in repository — pb_releases","text":"","code":"# \\donttest{ try({ # wrapped in try block to prevent CRAN errors  pb_releases(\"nflverse/nflverse-data\") }) #>          release_name release_id #> 1        ftn_charting  119740650 #> 2           espn_data  121931789 #> 3      weekly_rosters   73313637 #> 4  players_components  109160206 #> 5             players   69785162 #> 6   pbp_participation   71636554 #> 7           officials   69773595 #> 8                misc   69471165 #> 9                test   66262662 #> 10        draft_picks   66254658 #> 11          contracts   65273753 #> 12        snap_counts   58153010 #> 13            rosters   58152863 #> 14       player_stats   58152881 #> 15       pfr_advstats   58152981 #> 16                pbp   58152862 #> 17      nextgen_stats   58152931 #> 18           injuries   58152949 #> 19       depth_charts   58152948 #> 20            combine   60901499 #>                                                                                                                                                                                            release_body #> 1                                                                                                                                                                 Charting Data provided by FTNData.com #> 2                                                                                                                                                                                            ESPN Stats #> 3                                                                                                                                       Week-level rosters via NFL Shield v2 API, dating back to 2002.  #> 4                                                                                                                                                            Component files for nflverse players build #> 5                                                                                                Player information for nflverse. This should be the go-to for position and ID mappings going forward.  #> 6                                                                                                                                                                 Participation data for plays from NGS #> 7                                                                                                                             Data about which referees and officials were assigned to specific games.  #> 8  Various bits of data stored here as onetime jobs. Not automatically updated. Please file an issue or mention it on discord if you'd like to request something be maintained on an automatic schedule #> 9                                                                                                                                                                                  for internal testing #> 10                                                        Draft picks dating back to 1980, courtesy of Pro Football Reference. \\r\\n\\r\\nIncludes some career-level and ApproxValue/HOF/MVP/PB stats.\\r\\n #> 11                                                                                                                                OverTheCap contract data, accessed with `nflreadr::load_contracts()`. #> 12                                                                                                      Snap counts data, accessed with `nflreadr::load_snap_counts()`.\\r\\n\\r\\nLast Updated: 2022-03-06 #> 13                                                                                                                                                Roster data, accessed with `nflreadr::load_rosters()` #> 14                                                                                                                                     Play by play data, accessed with `nflreadr::load_player_stats()` #> 15                                                                                                                        PFR Adv Stats data, accessed with `nflreadr::load_pfr_advstats()`\\r\\n\\r\\n\\r\\n #> 16                                                                                                                                              Play by play data, accessed with `nflreadr::load_pbp()` #> 17                                                                                                                              NFL Next Gen Stats data, accessed with `nflreadr::load_nextgen_stats()` #> 18                                                                                                                                             Injuries data, accessed with `nflreadr::load_injuries()` #> 19                                                                                                                                      Depth chart data, accessed with `nflreadr::load_depth_charts()` #> 20                                                                                NFL Combine Data courtesy of PFR, accessed with `nflreadr::load_combine()`. \\r\\n\\r\\nLast Updated: 2022-03-05 17:06:33 #>              tag_name draft latest           created_at         published_at #> 1        ftn_charting FALSE  FALSE 2023-09-01T02:16:48Z 2023-09-03T16:14:36Z #> 2           espn_data FALSE  FALSE 2023-09-01T02:16:48Z 2023-09-20T19:50:55Z #> 3      weekly_rosters FALSE  FALSE 2022-06-15T16:58:26Z 2022-08-01T07:45:30Z #> 4  players_components FALSE  FALSE 2022-06-15T16:58:26Z 2023-06-20T01:22:44Z #> 5             players FALSE  FALSE 2022-06-15T16:58:26Z 2022-06-19T05:36:22Z #> 6   pbp_participation FALSE  FALSE 2022-06-15T16:58:26Z 2022-07-10T04:32:49Z #> 7           officials FALSE  FALSE 2022-06-15T16:58:26Z 2022-06-18T17:47:11Z #> 8                misc FALSE  FALSE 2022-05-29T16:57:43Z 2022-06-14T23:46:04Z #> 9                test FALSE  FALSE 2022-05-06T19:04:21Z 2022-05-06T19:56:46Z #> 10        draft_picks FALSE  FALSE 2022-05-06T18:12:18Z 2022-05-06T18:15:12Z #> 11          contracts FALSE  FALSE 2022-03-21T14:03:51Z 2022-04-25T19:40:32Z #> 12        snap_counts FALSE  FALSE 2022-01-28T02:09:45Z 2022-01-28T02:15:02Z #> 13            rosters FALSE  FALSE 2022-01-28T02:09:45Z 2022-01-28T02:12:10Z #> 14       player_stats FALSE  FALSE 2022-01-28T02:09:45Z 2022-01-28T02:12:36Z #> 15       pfr_advstats FALSE  FALSE 2022-01-28T02:09:45Z 2022-01-28T02:14:24Z #> 16                pbp FALSE   TRUE 2022-01-28T02:09:45Z 2022-01-28T02:12:09Z #> 17      nextgen_stats FALSE  FALSE 2022-01-28T02:09:45Z 2022-01-28T02:13:25Z #> 18           injuries FALSE  FALSE 2022-01-28T02:09:45Z 2022-01-28T02:13:49Z #> 19       depth_charts FALSE  FALSE 2022-01-28T02:09:45Z 2022-01-28T02:13:47Z #> 20            combine FALSE  FALSE 2022-01-28T02:09:45Z 2022-03-03T15:51:29Z #>                                                                     html_url #> 1        https://github.com/nflverse/nflverse-data/releases/tag/ftn_charting #> 2           https://github.com/nflverse/nflverse-data/releases/tag/espn_data #> 3      https://github.com/nflverse/nflverse-data/releases/tag/weekly_rosters #> 4  https://github.com/nflverse/nflverse-data/releases/tag/players_components #> 5             https://github.com/nflverse/nflverse-data/releases/tag/players #> 6   https://github.com/nflverse/nflverse-data/releases/tag/pbp_participation #> 7           https://github.com/nflverse/nflverse-data/releases/tag/officials #> 8                https://github.com/nflverse/nflverse-data/releases/tag/misc #> 9                https://github.com/nflverse/nflverse-data/releases/tag/test #> 10        https://github.com/nflverse/nflverse-data/releases/tag/draft_picks #> 11          https://github.com/nflverse/nflverse-data/releases/tag/contracts #> 12        https://github.com/nflverse/nflverse-data/releases/tag/snap_counts #> 13            https://github.com/nflverse/nflverse-data/releases/tag/rosters #> 14       https://github.com/nflverse/nflverse-data/releases/tag/player_stats #> 15       https://github.com/nflverse/nflverse-data/releases/tag/pfr_advstats #> 16                https://github.com/nflverse/nflverse-data/releases/tag/pbp #> 17      https://github.com/nflverse/nflverse-data/releases/tag/nextgen_stats #> 18           https://github.com/nflverse/nflverse-data/releases/tag/injuries #> 19       https://github.com/nflverse/nflverse-data/releases/tag/depth_charts #> 20            https://github.com/nflverse/nflverse-data/releases/tag/combine #>                                                                                        upload_url #> 1  https://uploads.github.com/repos/nflverse/nflverse-data/releases/119740650/assets{?name,label} #> 2  https://uploads.github.com/repos/nflverse/nflverse-data/releases/121931789/assets{?name,label} #> 3   https://uploads.github.com/repos/nflverse/nflverse-data/releases/73313637/assets{?name,label} #> 4  https://uploads.github.com/repos/nflverse/nflverse-data/releases/109160206/assets{?name,label} #> 5   https://uploads.github.com/repos/nflverse/nflverse-data/releases/69785162/assets{?name,label} #> 6   https://uploads.github.com/repos/nflverse/nflverse-data/releases/71636554/assets{?name,label} #> 7   https://uploads.github.com/repos/nflverse/nflverse-data/releases/69773595/assets{?name,label} #> 8   https://uploads.github.com/repos/nflverse/nflverse-data/releases/69471165/assets{?name,label} #> 9   https://uploads.github.com/repos/nflverse/nflverse-data/releases/66262662/assets{?name,label} #> 10  https://uploads.github.com/repos/nflverse/nflverse-data/releases/66254658/assets{?name,label} #> 11  https://uploads.github.com/repos/nflverse/nflverse-data/releases/65273753/assets{?name,label} #> 12  https://uploads.github.com/repos/nflverse/nflverse-data/releases/58153010/assets{?name,label} #> 13  https://uploads.github.com/repos/nflverse/nflverse-data/releases/58152863/assets{?name,label} #> 14  https://uploads.github.com/repos/nflverse/nflverse-data/releases/58152881/assets{?name,label} #> 15  https://uploads.github.com/repos/nflverse/nflverse-data/releases/58152981/assets{?name,label} #> 16  https://uploads.github.com/repos/nflverse/nflverse-data/releases/58152862/assets{?name,label} #> 17  https://uploads.github.com/repos/nflverse/nflverse-data/releases/58152931/assets{?name,label} #> 18  https://uploads.github.com/repos/nflverse/nflverse-data/releases/58152949/assets{?name,label} #> 19  https://uploads.github.com/repos/nflverse/nflverse-data/releases/58152948/assets{?name,label} #> 20  https://uploads.github.com/repos/nflverse/nflverse-data/releases/60901499/assets{?name,label} #>    n_assets #> 1        10 #> 2        10 #> 3        90 #> 4        10 #> 5         6 #> 6        34 #> 7         6 #> 8        17 #> 9         2 #> 10        6 #> 11        7 #> 12       51 #> 13      418 #> 14      392 #> 15      138 #> 16      150 #> 17       86 #> 18       62 #> 19       94 #> 20        6 # }"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_upload.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload data to an existing release — pb_upload","title":"Upload data to an existing release — pb_upload","text":"NOTE: must first create release one already exists.","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_upload.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload data to an existing release — pb_upload","text":"","code":"pb_upload(   file,   repo = guess_repo(),   tag = \"latest\",   name = NULL,   overwrite = \"use_timestamps\",   use_timestamps = NULL,   show_progress = getOption(\"piggyback.verbose\", default = interactive()),   .token = gh::gh_token(),   dir = NULL )"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_upload.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload data to an existing release — pb_upload","text":"file string: path file uploaded repo string: GH repository name format \"owner/repo\". Default guess_repo() tries guess based current working directory's git repository tag string: tag GH release, defaults \"latest\" name string: name uploaded file. provided use basename file (.e. filename without directory) overwrite choice: overwrite existing file name already attached release? Options \"use_timestamps\", TRUE, FALSE: default \"use_timestamps\" overwrite files release timestamp newer local file. use_timestamps DEPRECATED. show_progress logical, show progress bar shown uploading? Defaults interactive() - can also set globally options(\"piggyback.verbose\") .token GitHub authentication token, see gh::gh_token() dir directory relative file names based, defaults NULL current working directory.","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_upload.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upload data to an existing release — pb_upload","text":"","code":"if (FALSE) { # Needs your real token to run  readr::write_tsv(mtcars,\"mtcars.tsv.xz\") pb_upload(\"mtcars.tsv.xz\", \"cboettig/piggyback-tests\") }"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_write.html","id":null,"dir":"Reference","previous_headings":"","what":"Write one object to repo/release — pb_write","title":"Write one object to repo/release — pb_write","text":"convenience wrapper around writing object temporary file uploading specified repo/release.","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_write.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write one object to repo/release — pb_write","text":"","code":"pb_write(   x,   file,   ...,   repo = guess_repo(),   tag = \"latest\",   write_function = guess_write_function(file),   .token = gh::gh_token() )"},{"path":"https://docs.ropensci.org/piggyback/reference/pb_write.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write one object to repo/release — pb_write","text":"x object: memory object save piggyback file string: file name ... additional arguments passed write_function repo string: GH repository name format \"owner/repo\". Default guess_repo() tries guess based current working directory's git repo tag string: tag GH release, defaults \"latest\" write_function function: used write R object file, object passed first argument, filename second argument, additional arguments subsequently passed via .... Default guess_write_function(file) check file extension try find appropriate write function extension one rds, csv, tsv, parquet, txt, json, abort found. .token GitHub authentication token, see gh::gh_token()","code":""},{"path":"https://docs.ropensci.org/piggyback/reference/pb_write.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write one object to repo/release — pb_write","text":"Writes file release returns github API response","code":""},{"path":[]},{"path":"https://docs.ropensci.org/piggyback/reference/pb_write.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write one object to repo/release — pb_write","text":"","code":"# \\donttest{ if (interactive()) {   pb_write(mtcars, \"mtcars.rds\", repo = \"tanho63/piggyback-tests\")   #> ℹ Uploading to latest release: \"v0.0.2\".   #> ℹ Uploading mtcars.rds ...   #> |===============================================================| 100% } # }"},{"path":"https://docs.ropensci.org/piggyback/reference/piggyback-package.html","id":null,"dir":"Reference","previous_headings":"","what":"piggyback: Managing Larger Data on a GitHub Repository — piggyback-package","title":"piggyback: Managing Larger Data on a GitHub Repository — piggyback-package","text":"larger (> 50 MB) data files easily committed git, different approach required manage data associated analysis GitHub repository.  package provides simple work-around allowing larger (2 GB) data files piggyback repository assets attached individual GitHub releases.  files handled git way, instead uploaded, downloaded, edited directly calls GitHub API. data files can versioned manually creating different releases.  approach works equally well public private repositories.  Data can uploaded downloaded programmatically scripts. authentication required download data public repositories.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/piggyback/reference/piggyback-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"piggyback: Managing Larger Data on a GitHub Repository — piggyback-package","text":"Maintainer: Carl Boettiger cboettig@gmail.com (ORCID) [copyright holder] Authors: Tan Ho (ORCID) contributors: Mark Padgham (ORCID) [contributor] Jeffrey O Hanson (ORCID) [contributor] Kevin Kuo (ORCID) [contributor]","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-development-version","dir":"Changelog","previous_headings":"","what":"piggyback (development version)","title":"piggyback (development version)","text":"Fix bug pb_releases() allow draft releases appear [#105] pb_upload() longer offers create release interactive - now provides code create release error body. pb_download() now tries uses browser download URLs (.e. pb_download_url()) trying API download URLs. reduce/eliminate effect API rate limits pb_download. [#109] \"latest\" release now aligns GitHub’s “latest” release definition [#113] pb_download_url() now can return choice “browser” “api” download URLs [#116] Add new functions pb_read() pb_write() convenience wrappers around pattern downloading tempfile() reading memory. [#97]","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-015","dir":"Changelog","previous_headings":"","what":"piggyback 0.1.5","title":"piggyback 0.1.5","text":"CRAN release: 2023-07-10 Fix bug pb_upload() correctly resolve \"latest\" tag - release tag actually named “latest” use first release pb_releases(). [#75] Make pb_download() pb_info() also resolve \"latest\" similarly: release tag named “latest”, use first release pb_releases() Updated test coverage use GHA Fixed error handling pb_list() release. pb_list() now respects option \"piggyback.verbose\" Fix download token handling [#88] pb_upload() longer prints extra newlines [#93] pb_new_release() now warns exits early instead failing release already exists. [#95] Fixup test issues [#100] takes seconds GitHub API register new release created Adds piggyback.cache R option avoid memoising altogether Adds .pb_cache_clear() function empty cache consistently (internally externally)","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-014","dir":"Changelog","previous_headings":"","what":"piggyback 0.1.4","title":"piggyback 0.1.4","text":"CRAN release: 2022-07-19 progress bar argument show_progress pb_upload() pb_download() now defaults interactive() [#72] Fix bug pb_download() downloading without gh::gh_token() (mostly Windows?) [#77] Fix bug introduced bugfix - missed Authorization header guess_repo() now uses gh::gh_tree_remote() rather gert - eliminates gert dependency. [#80] pb_release_delete() introduced delete existing releases. [#81] pb_new_release() renamed pb_release_create() sync new delete function. Fix offer create new release pb_upload() - also switch using rlang::is_interactive() maybe one day test . Tests rewritten primarily use GHA write /ropensci/piggyback repo. Added httr::RETRY() behaviour pb_download().","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-013","dir":"Changelog","previous_headings":"","what":"piggyback 0.1.3","title":"piggyback 0.1.3","text":"CRAN release: 2022-05-19 fix bug pb_upload() uploading release assets [#67] avoid implicit dependency tibble [#70]","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-012","dir":"Changelog","previous_headings":"","what":"piggyback 0.1.2","title":"piggyback 0.1.2","text":"CRAN release: 2022-04-26 update intro vignette remove mentions pb_track(), pb_push(), pb_pull() removed version 0.0.0.9900 pb_upload() now handles dir argument control relative path directories. update intro vignette remove mention path name handling instead provide examples path names handled. update intro vignette instructions git authentication pb_new_release() now reports HTTP errors attempting create new release returns contents error fails. pb_releases() created - returns list releases available repository. Internal function pb_info() refactored search specified tag(s) improve performance. handle multiple tags gracefully. Internal function pb_info() (therefore pb_list(), pb_download(), pb_download_url()) longer ask creating new releases release found. pb_upload() now function offers (interactively) create new release release found. noninteractive, user must run pb_new_release() manually prior uploading. CLI messaging now consistently uses cli package longer uses clisymbols crayon - align imports gh package. Documentation updated. Add options(“piggyback.verbose”) TRUE/FALSE control verbosity/messaging levels.","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-011","dir":"Changelog","previous_headings":"","what":"piggyback 0.1.1","title":"piggyback 0.1.1","text":"CRAN release: 2021-09-09 switch gh::gh_token() token management. Still supports env var approach, also compatible gitcreds use. resolve issue pb_upload() creating new tag process, previously data attached previously latest tag instead newly created one. resolve issue pb_download() httr report 401 status even data successfully downloads.","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-010","dir":"Changelog","previous_headings":"","what":"piggyback 0.1.0","title":"piggyback 0.1.0","text":"CRAN release: 2021-08-06 address remaining authentication issue changes GitHub API (pb_upload()) [#47] Use flat file structure upload/download instead encoding path [#48] improve performance via aggressive memoising pb_info() calls, inceasing default piggyback_cache_duration 10 minutes [#46] Resolve bug introduced API changes stop creation tags repos default branch called main without previous releases [#48]","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-0012","dir":"Changelog","previous_headings":"","what":"piggyback 0.0.12","title":"piggyback 0.0.12","text":"address issues authentication due changes GitHub API (#37)","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-0011-2020-02-25","dir":"Changelog","previous_headings":"","what":"piggyback 0.0.11 2020-02-25","title":"piggyback 0.0.11 2020-02-25","text":"CRAN release: 2020-02-25 guess_repo() now infers remote multiple associated repo. “upstream” (preferred) “origin” repo selected either exists, otherwise function errors asks user explicitly specify repo (#31). release_info() now works properly existing releases, enables usage pb_new_release() repos without release (#29). Fix error pb_info() certain cases resulted Error [[1]] : subscript bounds, (#36) Fix CRAN unit-test deleting file","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-0010-2018-02-06","dir":"Changelog","previous_headings":"","what":"piggyback 0.0.10 2018-02-06","title":"piggyback 0.0.10 2018-02-06","text":"CRAN release: 2019-02-07 Improve interface regarding overwrite behavior pb_upload() (#25) Access assets release instead first 30. break upload download. (#23, #24) Uploading directory paths cause download errors pb_download(). (#24, #26)","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-009-2019-01-08","dir":"Changelog","previous_headings":"","what":"piggyback 0.0.9, 2019-01-08","title":"piggyback 0.0.9, 2019-01-08","text":"CRAN release: 2019-01-08 Enable re-upload deletion partially uploaded files (#19)","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-008-2018-10-06","dir":"Changelog","previous_headings":"","what":"piggyback 0.0.8, 2018-10-06","title":"piggyback 0.0.8, 2018-10-06","text":"CRAN release: 2018-10-06 Updates documentation, streamlining tests remove dependency utils::askYesNo available R >= 3.5.0","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-007-2018-09-30","dir":"Changelog","previous_headings":"","what":"piggyback 0.0.7, 2018-09-30","title":"piggyback 0.0.7, 2018-09-30","text":"CRAN release: 2018-09-30 Initial release CRAN","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-006-2018-09-21","dir":"Changelog","previous_headings":"","what":"piggyback 0.0.6, 2018-09-21","title":"piggyback 0.0.6, 2018-09-21","text":"bugfix migrating unit test","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-006-2018-09-21-1","dir":"Changelog","previous_headings":"","what":"piggyback 0.0.6, 2018-09-21","title":"piggyback 0.0.6, 2018-09-21","text":"bugfix migrating unit test, JOSS submission","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-005-2018-09-21","dir":"Changelog","previous_headings":"","what":"piggyback 0.0.5, 2018-09-21","title":"piggyback 0.0.5, 2018-09-21","text":"initial Onboarding rOpenSci","code":""},{"path":"https://docs.ropensci.org/piggyback/news/index.html","id":"piggyback-0009000","dir":"Changelog","previous_headings":"","what":"piggyback 0.0.0.9000","title":"piggyback 0.0.0.9000","text":"Added NEWS.md file track changes package.","code":""}]
